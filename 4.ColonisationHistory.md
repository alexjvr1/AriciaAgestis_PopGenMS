# UK colonisation history

Where were the new populations colonised from? We will use fastSimCoal to estimate the most likely colonisation history. 

We do not have the ancestral state, so I have to generate the [folded SFS](https://www.mun.ca/biology/scarr/SFS_&_FSFS.html) for each of the populations or groups of populations. That is, if all derived alleles are identified as compared with Indiv 1 (a random indiv in the population), then the frequency of the derived alleles are combined for classes i and (n-i), where i is the number of indivs in the population. 

An [example paper](https://nph.onlinelibrary.wiley.com/doi/full/10.1111/nph.14951#nph14951-fig-0002) from the Sork lab. 

And [another](https://onlinelibrary.wiley.com/doi/full/10.1111/mec.15132?casa_token=iTjBMCiloY4AAAAA%3AY2wNHk41rqTXJXb077LRnuAsWMoe0LGFBuPcFpLA0qLJ3gCpHeGePPmHqnMQc2C_LVXe7nTOcfbNcE8) from the Laurila group 


Vitor suggests we need at least 8000 loci otherwise the CI will overlap too much between models to choose a best model. 

## Filtering

We start with the unfiltered vcf file. Don't filter for MAF or any other filter that will affect the SFS. 

1. The dataset is filtered to remove any loci under selection, the Z chromosome, and mtDNA. 

NB - We're not filtering linked loci (i.e. --thin) because in the next step we will subsample SNPs within a linked block to obtain SFS data for each locus with enough data. 

2. Populations are downsampled to exclude all missing data using a python script available from the paper. 

3. Write 2D SFS for all population pairs specified in the input. 

4. Specify model for FastSimCoal and run


This was done on the server. 

## 1 First remove the Z chromosme and mtDNA from the full dataset. 
```
#VCF found here
/newhome/aj18951/1a_Aricia_agestis_GWASdata/03_variants

#Run here
/newhome/aj18951/1a_Aricia_agestis_PopGenomics/FastSimCoal

vcftools --vcf AAgestis.251_FINAL.newnames.vcf --not-chr SUPER_Z --not-chr scaffold_MT --recode --recode-INFO-all --out AA251.noMT.noZ.recode.vcf 

VCFtools - 0.1.17
(C) Adam Auton and Anthony Marcketta 2009

Parameters as interpreted:
	--vcf AA251.noMT.noZ.recode.vcf

After filtering, kept 251 out of 251 Individuals
After filtering, kept 129242 out of a possible 136624 Sites
Run Time = 2.00 seconds


```

Then remove all loci under selection and loci that deviate from HWE. For this I need to identify a list of outliers for 1) host plant preference, and 2) colonisation history. Three of these overlaps.
Then I need to identify loci not in HWE using vcftools --hardy, and select all loci with a p-value <0.05. 
```
pwd
/newhome/aj18951/1a_Aricia_agestis_PopGenomics/FastSimCoal

#create a bed file with all the outliers listed.
cat outliers_toremove.bed
SUPER_5 2534002 2534121
SUPER_8 3986655 3986867
SUPER_9 8813929 8814131
SUPER_16 1044346 1044290
SUPER_16 13191349 13191435
SUPER_18 7568031 7568229
SUPER_19 11604518 11604613
SUPER_22 3379790 3379920
SUPER_9 13750697 13750872
SUPER_9 13873437 13873517
SUPER_Z 39688177 39688352
SUPER_2 19346580 19346640
SUPER_3 13157714 13158002
SUPER_5 1546360 1546529
SUPER_7 10650285 10650289
SUPER_9 15951709 15951875
SUPER_10 14888691 14888843
SUPER_17 1198584 1198741
SUPER_18 2919521 2919551
SUPER_18 5119217 5119475
SUPER_18 5319947 5320001
SUPER_18 7677546 7677682
SUPER_19 7875580 7875833
SUPER_20 8466072 8466312
SUPER_Z 22737599 22737787
SUPER_Z 28513286 28513300


#Remove these from main vcf file

vcftools --vcf AA251.noMT.noZ.recode.vcf --exclude-bed outliers_and_het_toremove.bed 

VCFtools - 0.1.17
(C) Adam Auton and Anthony Marcketta 2009

Parameters as interpreted:
	--vcf AA251.noMT.noZ.recode.vcf
	--exclude-bed outliers_and_het_toremove.bed

After filtering, kept 251 out of 251 Individuals
	Read 612 BED file entries.
After filtering, kept 128565 out of a possible 129242 Sites
Run Time = 2.00 seconds

```



### LD

Calculate the mean linkage (r^2) between loci using vcftools to have an idea of how linked the loci are. 


```
/newhome/aj18951/1a_Aricia_agestis_PopGenomics/FINAL_VCF



##Copy output to mac
/Users/alexjvr/2018.postdoc/BrownArgus_2018/201902_DataAnalysis/LinkageDisequilibrium
scp bluecp3:/newhome/aj18951/1a_Aricia_agestis_PopGenomics/FINAL_VCF/out.ld.geno .


##R
library(ggplot2)

ld <- read.table("out.geno.ld", header=T)
head(ld)
ld$dist <- ld$POS2-ld$POS1  #distance between sites

pdf("BA_CHR9_r2.pdf")
ggplot(ld, aes(x=dist, y=R.2))+geom_line()+xlab("Distance, bp")+ylab("Average r2")+ggtitle("Linkage disequilibrium between all site pairs - CHR 9")
dev.off()

```

![alt_txt][LD]

[LD]:https://user-images.githubusercontent.com/12142475/120472727-28b2fd00-c39e-11eb-8e2e-246468101442.png



## 2. Downsample & 3. Write SFS

The [Process_VCFtoSFS](https://github.com/alexjvr1/AriciaAgestis_PopGenMS/blob/master/Process_VCFtoSFS.sh) script by [Vitor Sousa](https://github.com/vsousa/EG_cE3c/tree/master/CustomScripts/Fastsimcoal_VCFtoSFS) samples the maximum number of non-missing loci for each population at a locus. We specify the min number of individuals to sample per population. That means that different SNPs can be counted for differnt individuals, but because they're linked (at the same RADtag) we assume that they'll have the same MAF. 

We're creating DSFS because we have the Reference genome. 

```
#We're working here: 
/newhome/aj18951/1a_Aricia_agestis_PopGenomics/FastSimCoal

#1. Create a folder with all three Rscripts in:
mkdir Scripts_VCFtoSFS
ls Scripts_VCFtoSFS
> blockBootstrap_SFS.r  BlockSFS_jan2020.r  functions_resample.r

#2. If we're creating DSFS change the functions_resample.r functions_resample.r:  outfilename <- paste(outfiletag_sfs, "_DSFS.obs",sep="")  
#The code in Vitor's repository specifies MSFS

#3. Submit to server. 
#We're running this for three and four populations based on our demographic scenarios. 
qsub Process_VCFtoSFS.sh
```

This creates several single and joint SFS for the populations. 


## 4. Create FSC input files and run

Create .tpl and .est input files to specify the demographic model 

e.g. for our two basic models we want to compare if the new populations were colonised from the South or from HOD. 


```
#1. Create a directory for the model 
mkdir FULL_MODEL1 && cd FULL_MODEL1

#2. copy all SFS to this folder: 
cp AA251_3pops_SFS_1000bp_dist2_ind5_5_3/*obs .

#3. Create .tpl and .est inputs (see below)
##NB check that the sample sizes in the .tpl file is the same as was sampled in the .obs files (specified to the Process_VCFtoSFS.sh script). 
##We'll compare these SFS directly later on. 

```




file.tpl example
```
//Parameters for the coalescence simulation program : fsimcoal2.exe
3 samples to simulate :
//Population effective sizes (number of genes)
NNEW
NSOUTH
NHOD
//Samples sizes and samples age 
10
10
6
//Growth rates	: negative growth implies population expansion
0
0
0
//Number of migration matrices : 0 implies no migration between demes
1
//migration matrix
0 MIG01 MIG02
MIG10 0 MIG12
MIG20 MIG21 0
//historical event: time, source, sink, migrants, new deme size, new growth rate, migration matrix index
2
TDIV1 0 2 1 RESIZE 0 0
TDIV2 2 1 1 RESIZE 0 0
//Number of independent loci [chromosome] 
1 0
//Per chromosome: Number of contiguous linkage Block: a block is a set of contiguous loci
1
//per Block:data type, number of loci, per generation recombination and mutation rates and optional parameters
FREQ  1   0   2.5e-9 OUTEXP

```



file.est example 
```
// Priors and rules file
// *********************
[PARAMETERS]
//#isInt? #name #dist.#min #max
//all N are in number of haploid individuals
1 ANCSIZE unif 1000 1000000 output
1 NNEW unif 1000 1000000 output
1 NSOUTH unif 1000 1000000 output
1 NHOD unif 1000 1000000 output
1 TDIV1 unif 10 100 output
1 TPLUSDIV unif 10 10000 output
1 MIG01 unif 0 0.5 output
1 MIG10 unif 0 0.5 output
1 MIG02 unif 0 0.5 output
1 MIG20 unif 0 0.5 output
1 MIG12 unif 0 0.5 output
1 MIG21 unif 0 0.5 output
0 MUTRATE unif 2.9e-9 5.5e-9 output

[RULES]

[COMPLEX PARAMETERS]
0 RESIZE = ANCSIZE/NSOUTH output
0 TDIV2 = TDIV1+TPLUSDIV output
```



```
## 4. Edit and launch script to run several itirations of FSC
```
```
qsub FSC.BaseModel.ARRAY.sh -F "BA BaseModel BaseModel_ MSFS.obs 100"

poptag=$1 #Analysis name
tplEstTag=$2  #Prefix of est file
obsSFSfile=$3  #MSFS file prefix
obsFileEnding=$4  #MSFS (or other SFS) file suffix
numRuns=$5  #number of array jobs. But see below. I create the numRunsSeq2 file beforehand 

#Define Array names
#seq $baseRuns $numRuns >> numRunsSeq
#sed 's/^/Run/g' numRunsSeq >> numRunsSeq2
NAME=$(sed "${PBS_ARRAYID}q;d" numRunsSeq2)
```

File Organisation: 

The model directory should contain the SFS.obs, the .tpl and .est files, as well as the numRunsSeq2 file. All scripts (.sh) are in the same folder as the inputs: 

```
>ls BaseModel_Model2

BA-BaseModel_MSFS.obs         
BaseModel.est                 
BaseModel_jointMAFpop1_0.obs  
BaseModel_jointMAFpop2_0.obs  
BaseModel_jointMAFpop2_1.obs  
BaseModel.tpl
FSC.BaseModel.ARRAY.sh  
FSC.CollectResults.sh   
numRunsSeq2
```


After this is done we need to move the restuls up one directory. All results are written in Runxx (1-100), and then in a $ModelName folder. Move everything up one directory to be in the Run* folder. 
```
for dir in *; do mv "$dir"/BA-BaseModel/* "$dir"/; done
```

Check that this has worked. The bestlhoods file should be in directly in the Runx directory: 
```
>ls Run100/

BA-BaseModel             BA-BaseModel.bestlhoods    BA-BaseModel.est       BA-BaseModel_MSFS.obs  BA-BaseModel.par  BA-BaseModel.tpl
BA-BaseModel_1.simparam  BA-BaseModel.brent_lhoods  BA-BaseModel_maxL.par  BA-BaseModel_MSFS.txt  BA-BaseModel.pv   seed.txt
```

And summarise all the results to create the xx_ALL.param file
Script to summarise all the results of a particular model: [FSC.CollectResults.sh](https://github.com/alexjvr1/AriciaAgestis_PopGenMS/blob/master/4f_FSC.CollectResults.sh)



## 5. Collect the results


Collect all the results together using the [FSC.CollectResults.sh](https://github.com/alexjvr1/AriciaAgestis_PopGenMS/blob/master/FSC.CollectResults.sh) script

```
./FSC.CollectResults.sh

```


## Analyse outputs

I'm analysing the outputs using [Vitor's scripts](https://github.com/vsousa/EG_cE3c/blob/c3a8871220cc0fef31f1bc0e347e3d295f2d7d93/CustomScripts/Fastsimcoal_ProcessOutput/Scripts_AnalyseFsc/utilFscOutput.r) modified for the Array job outputs. 

My versions can be found here: 

[AnalyseFscResults.r]()

[ParFileInterpreter_VS.r]()

[utilFscOutput.r]()


These need to be run on the mac. 

R version 3.5.0

1. Copy all the outputs to the mac: 
```
>ls /Users/alexjvr/2018.postdoc/BrownArgus_2018/201902_DataAnalysis/FastSimCoal/2020_AnalyseOutputs

AnalyseFscResults.r				
ParFileInterpreter_VS.r
utilFscOutput.r

##make a directory for the model to be analysed and copy all outputs from bluecrystal: 

mkdir BA-BaseModel_Model2 
cd BA-BaseModel_Model2

scp -r bluecp3:/newhome/aj18951/1a_Aricia_agestis_PopGenomics/FastSimCoal/BaseModel_Model2/*obs .
scp -r bluecp3:/newhome/aj18951/1a_Aricia_agestis_PopGenomics/FastSimCoal/BaseModel_Model2/Run* .
scp -r bluecp3:/newhome/aj18951/1a_Aricia_agestis_PopGenomics/FastSimCoal/BaseModel_Model2/*_ALL.param .

## rename the two files: 
mv BA-BaseModel_MSFS.obs BaseModel_MSFS.obs
mv BA-BaseModel_ALL.param BA-BaseModel_Model2_ALL.param

cd ..
```

2. Edit the Settings section in AnalyseFscResults.r:
```
####################
## Settings       ##
####################

settings <- list()
# population tag
settings$poptag <- "BA"
# model tag
settings$modeltag <- "BaseModel_Model1"
#filenames added by AJvR
settings$filename <- "BA-BaseModel"
# population names according to order in Obs SFS
settings$pop.names <- c("SOUTH", "FOR", "HOD")
# path to folder with results
# here if your results are in a server you could use
# username@server.address:/folderInServer
settings$pathtofolder <- paste(settings$poptag, "-", settings$modeltag, sep="")
# observed SFS file name and path used to get maximum likelihood estimates
# this can contain linked SNPs
settings$obsfilename <- paste(settings$poptag, "-", settings$modeltag, "/BaseModel_MSFS.obs", sep="")
# observed SFS with only independent SNPs
settings$obsfilename_unlinkedSNPs <- paste(settings$poptag, "-", settings$modeltag, "/BaseModel_MSFS.obs", sep="")
# need an option for multi-SFS
settings$multiSFS <- TRUE
# -C option with minimum SFS counts. All entries with less than -C are pooled together
settings$minentry <- 1
```

3. Run the script
```
Rscript AnalyseFscResults.r
```

### Results

BaseModel 1 vs 2

Model1
```
In dir.create(folderName) : 'BA-BaseModel_Model1' already exists
[1] TRUE
      ANCSIZE        NSOUTH          NHOD          NFOR         TDIV1 
 7.940500e+04  1.020980e+05  2.404500e+04  1.286300e+04  5.310000e+02 
     TPLUSDIV         MIG01         MIG10         MIG02         MIG20 
 1.750000e+02  0.000000e+00  0.000000e+00  0.000000e+00  0.000000e+00 
        MIG12         MIG21       MUTRATE        RESIZE         TDIV2 
 0.000000e+00  0.000000e+00  4.495430e-09  7.777332e-01  7.060000e+02 
  MaxEstLhood   MaxObsLhood 
-4.498638e+03 -4.470925e+03 
cp: ./BA-BaseModel_Model1/Run10 and BA-BaseModel_Model1/Run10 are identical (not copied).
Read 4 items
Read 41412 items
Read 41412 items
[1] "Sum of entries of expected SFS==0 is  29576"
[1] "Sum of entries of observed SFS==0 is  20707"
null device 
          1 
[1] "./BA-BaseModel_Model1/Run10/BA-BaseModel_maxL"
Read 30 items
Loading required package: shape
null device 
          1 
Read 4 items
Read 41412 items
Read 41412 items
$AIC
[1] 20747.78

$loglhood
[1] -4499.244
```


Model2
```
In dir.create(folderName) : 'BA-BaseModel_Model2' already exists
[1] TRUE
      ANCSIZE        NSOUTH          NHOD          NFOR         TDIV1 
 2.033599e+06  5.901520e+05  1.325800e+05  8.856200e+04  4.761000e+03 
     TPLUSDIV         MIG01         MIG10         MIG02         MIG20 
 4.300000e+01  0.000000e+00  0.000000e+00  0.000000e+00  0.000000e+00 
        MIG12         MIG21       MUTRATE        RESIZE         TDIV2 
 0.000000e+00  0.000000e+00  3.993450e-09  3.445890e+00  4.804000e+03 
  MaxEstLhood   MaxObsLhood 
-4.509396e+03 -4.470925e+03 
cp: ./BA-BaseModel_Model2/Run30 and BA-BaseModel_Model2/Run30 are identical (not copied).
Read 4 items
Read 41412 items
Read 41412 items
[1] "Sum of entries of expected SFS==0 is  29783"
[1] "Sum of entries of observed SFS==0 is  20707"
null device 
          1 
[1] "./BA-BaseModel_Model2/Run30/BA-BaseModel_maxL"
Read 30 items
Loading required package: shape
null device 
          1 
Read 4 items
Read 41412 items
Read 41412 items
$AIC
[1] 20797.31

$loglhood
[1] -4509.998
```



# FINAL model with 3 pops (excluding FOR)


```
ls /newhome/aj18951/1a_Aricia_agestis_PopGenomics/FastSimCoal/FINALmodel_Model1

FSC.FULLModel.ARRAY.sh  
FullModel_jointMAFpop2_0.obs  
FullModel_jointMAFpop3_2.obs  
NEW_MAFpop0.obs
FullModel_jointMAFpop2_1.obs  
BA-FullModel_MSFS.obs            
numRunsSeq2      
Run4
FOR_MAFpop0.obs  
FullModel.est  
FullModel_jointMAFpop3_0.obs  
FullModel.tpl             
SOUTH_MAFpop0.obs
FSC.CollectResults.sh  
FullModel_jointMAFpop1_0.obs     
FullModel_jointMAFpop3_1.obs  
HOD_MAFpop0.obs


qsub FSC.FULLModel.ARRAY.sh -F "BA FinalModel FinalModel_ MSFS.obs 100"

```


##### RESULTS

Edit the Settings section in AnalyseFscResults.r
```
####################
## Settings       ##
####################

settings <- list()
# population tag
settings$poptag <- "BA"
# model tag
settings$modeltag <- "FinalModel_Model1"
#filenames added by AJvR
settings$filename <- "BA-FinalModel"
# population names according to order in Obs SFS
settings$pop.names <- c("NEW", "SOUTH", "HOD")
# path to folder with results
# here if your results are in a server you could use
# username@server.address:/folderInServer
settings$pathtofolder <- paste(settings$poptag, "-", settings$modeltag, sep="")
# observed SFS file name and path used to get maximum likelihood estimates
# this can contain linked SNPs
settings$obsfilename <- paste(settings$poptag, "-", settings$modeltag, "/FinalModel_MSFS.obs", sep="")
# observed SFS with only independent SNPs
settings$obsfilename_unlinkedSNPs <- paste(settings$poptag, "-", settings$modeltag, "/FinalModel_MSFS.obs", sep="")
# need an option for multi-SFS
settings$multiSFS <- TRUE
# -C option with minimum SFS counts. All entries with less than -C are pooled together
settings$minentry <- 1
```




FinalModel1
```
Warning message:
In dir.create(folderName) : 'BA-FinalModel_Model1' already exists
[1] TRUE
      ANCSIZE          NNEW        NSOUTH          NHOD         TDIV1 
 1.430870e+05  2.228700e+04  1.249370e+05  1.545400e+04  2.990000e+02 
     TPLUSDIV         MIG01         MIG10         MIG02         MIG20 
 2.930000e+02  0.000000e+00  0.000000e+00  0.000000e+00  0.000000e+00 
        MIG12         MIG21       MUTRATE        RESIZE         TDIV2 
 0.000000e+00  0.000000e+00  4.392600e-09  1.145273e+00  5.920000e+02 
  MaxEstLhood   MaxObsLhood 
-4.537903e+03 -4.506546e+03 
cp: ./BA-FinalModel_Model1/Run52 and BA-FinalModel_Model1/Run52 are identical (not copied).
Read 4 items
Read 265524 items
Read 265524 items
[1] "Sum of entries of expected SFS==0 is  229902"
[1] "Sum of entries of observed SFS==0 is  132763"
null device 
          1 
[1] "./BA-FinalModel_Model1/Run52/BA-FinalModel_maxL"
Read 30 items
Loading required package: shape
null device 
          1 
Read 4 items
Read 265524 items
Read 265524 items
$AIC
[1] 21021.64

$loglhood
[1] -4558.71
```


FinalModel2
```
Warning message:
In dir.create(folderName) : 'BA-FinalModel_Model2' already exists
[1] TRUE
      ANCSIZE          NNEW        NSOUTH          NHOD         TDIV1 
 1.954480e+05  4.888000e+03  2.339600e+04  4.698000e+03  1.330000e+02 
     TPLUSDIV         MIG01         MIG10         MIG02         MIG20 
 2.800000e+01  0.000000e+00  0.000000e+00  0.000000e+00  0.000000e+00 
        MIG12         MIG21       MUTRATE        RESIZE         TDIV2 
 0.000000e+00  0.000000e+00  4.285580e-09  8.353907e+00  1.610000e+02 
  MaxEstLhood   MaxObsLhood 
-4.568141e+03 -4.506546e+03 
cp: ./BA-FinalModel_Model2/Run15 and BA-FinalModel_Model2/Run15 are identical (not copied).
Read 4 items
Read 265524 items
Read 265524 items
[1] "Sum of entries of expected SFS==0 is  222609"
[1] "Sum of entries of observed SFS==0 is  132763"
null device 
          1 
[1] "./BA-FinalModel_Model2/Run15/BA-FinalModel_maxL"
Read 30 items
Loading required package: shape
null device 
          1 
Read 4 items
Read 265524 items
Read 265524 items
$AIC
[1] 21069.54

$loglhood
[1] -4569.111
```




## 6. LRT and process output

Transfer all results to Mac and run LRT to determine the best model. 

```







################
# DID NOT WORK
################ 
## Input files

Generating the input files for fastSimCoal2

### 1) SFS

I'm using [this](https://github.com/shenglin-liu/vcf2sfs) R script to generate a folded SFS for FOR (called North), HOD, South, and New populations. 

I need a vcf file with a popmap file: 
```
/Users/alexjvr/2018.postdoc/BrownArgus_2018/201902_DataAnalysis/FastSimCoal

#write all the indiv names to file
bcftools query -l AA261.Neutral.thin.recode.vcf > popmap.AA261 
#write all the popnames to file
awk -F'_' '{print $0}' popmap.AA261 > popnames
#add together
print popmap.AA261 popnames > popmap.AA261.2
rm popmap.AA261 && mv popmap.AA261.2 popmap.AA261
head popmap.AA261 
BAR_10_2013	BAR
BAR_11_2014	BAR
BAR_12_2013	BAR
BAR_13_2014	BAR
```

And download the R script for the above link. The function vcf2sfs.r is stored in the FastSimCoal folder where all these analyses are being run.
Open R: 
```
source("vcf2sfs.r")
mygt <- vcf2gt("AA261.Neutral.thin.recode.vcf", "popmap.AA261")   ##read in the vcf file and popmap files

viewMissing(mygt) ##look at the distribution of missing data
```

#### Distribution of missing data in the dataset

![alt_txt][Missing.data]

[Missing.data]:https://user-images.githubusercontent.com/12142475/76212667-e3d30180-6200-11ea-9427-de8c11ee6a36.png

Filter missing data and subset the populations
```
mygt.filtered <- filter.gt(mygt, filter.indi=NA, filter.snp=T) ##if I filter individuals with missing data all data are removed! This current filter leaves me with only 130 SNPs! This is too few for fastSimCoal. I need at least 2000 loci, although I can remove more individuals. 
Splitting the dataset up into the different groups slightly increases the number of fully genotyped SNPs, but this is still well under 1000 for all groups. 
```
We need several 1000 loci for fastSimCoal to work effectively. See Laurent Excoffier's comment [here](https://groups.google.com/forum/#!topic/fastsimcoal/E_GdjQCGPtU). The current dataset doesn't lend itself to this analysis. One option is to downsample the number of individuals in the dataset. A second option is to partition the dataset into the different groups and then impute the missing data within each dataset. Laurent Excoffier [doesn't like this approach](https://groups.google.com/forum/#!topic/fastsimcoal/czVzOGrPEb8).

Strategy: 

I will remove individuals with the most missing data and downsample to the same number of samples per group. Then I will impute (or should I impute first? But then the groups with larger sample sizes will have a better imputation?). 

The question is how does BEAGLE 1) phase haplotypes and 2) Impute missing genotypes when there is population structure in the dataset. Is it better to split the dataset into the geographic regions first? 

Compromise: 

Remove all indivs with > x% missing data (a low %). Then impute the missing data. The papers I've seen all downsample the geographic regions to include only indivs with a high genotyping rate. In some cases this is as low as [4 indivs!](https://www.ncbi.nlm.nih.gov/pmc/articles/PMC6128945/), although all MSs have a larger dataset than us (min 5668 loci). 

We start off with 31k loci, but thin down to ~3000 to reduce linkage in the dataset. 

What % missingness will we allow? There's the usual trade-off between missingness and the number of individuals that drop out
```
vcftools --vcf AA261.Neutral.thin.recode.vcf --missing-indv

AJvR:FastSimCoal alexjvr$ awk '$5>0.06 {print $1}' out.imiss |wc -l
     140
AJvR:FastSimCoal alexjvr$ awk '$5>0.07 {print $1}' out.imiss |wc -l
      89
AJvR:FastSimCoal alexjvr$ awk '$5>0.08 {print $1}' out.imiss |wc -l
      51
AJvR:FastSimCoal alexjvr$ awk '$5>0.09 {print $1}' out.imiss |wc -l
      44
AJvR:FastSimCoal alexjvr$ awk '$5>0.1 {print $1}' out.imiss |wc -l
      39
```
There's a big difference in the number of indivs with max 6% vs 7% missingness. If I reduce down to 6% the North group (HOD) contains only 3 indivs. I think this is too few. So I will use a cut-off of max 7% missingness. And impute the 7% missing data using BEAGLE. 

```
vcftools --vcf AA261.Neutral.thin.recode.vcf --missing-indv

awk '$5>0.07 {print $1}' out.imiss > indivstoremove

vcftools --vcf AA261.Neutral.thin.recode.vcf --remove indivstoremove --recode --recode-INFO-all --out AA261.Neutral.thin.maxmissing0.07percent

VCFtools - 0.1.17
(C) Adam Auton and Anthony Marcketta 2009

Parameters as interpreted:
	--vcf AA261.Neutral.thin.recode.vcf
	--remove indivstoremove
	--recode-INFO-all
	--out AA261.Neutral.thin.maxmissing0.07percent
	--recode

Warning: Expected at least 2 parts in INFO entry: ID=PV4,Number=4,Type=Float,Description="P-values for strand bias, baseQ bias, mapQ bias and tail distance bias">
Warning: Expected at least 2 parts in INFO entry: ID=PV4,Number=4,Type=Float,Description="P-values for strand bias, baseQ bias, mapQ bias and tail distance bias">
Warning: Expected at least 2 parts in INFO entry: ID=DP4,Number=4,Type=Integer,Description="Number of high-quality ref-forward , ref-reverse, alt-forward and alt-reverse bases">
Warning: Expected at least 2 parts in INFO entry: ID=DP4,Number=4,Type=Integer,Description="Number of high-quality ref-forward , ref-reverse, alt-forward and alt-reverse bases">
Excluding individuals in 'exclude' list
After filtering, kept 173 out of 261 Individuals
Outputting VCF file...
After filtering, kept 3486 out of a possible 3486 Sites
Run Time = 3.00 seconds

```

##### Phase and impute using Beagle 5.1


```

```


##### Calculate the folded SFS

######### Tests

1) Test the coalescent model with just a single model first: Divergence between South and HOD. 

Split the vcf file to include only South and HOD. Create the poplist

Then in R: 
```
/Users/alexjvr/2018.postdoc/BrownArgus_2018/201902_DataAnalysis/FastSimCoal/test/Test1_HOD.South

source("../vcf2sfs.r")

mygt <- vcf2gt("South.HOD.Test.recode.vcf", "names")  ##read in

##calculate SFS & fold
mysfs <- gt2sfs.raw(mygt, c("South", "HOD"))
fold.mysfs <- fold.sfs(mysfs)

plot.sfs(fold.mysfs)

write.2D.fsc(fold.mysfs, "South.HOD.sfs")  ##This script can only write 1D or 2D SFS. So I'll need a different script for the 3pop files. Also later there will be 4-5 demes! 
```
![alt_txt][fold.mysfs.Test1]

[fold.mysfs.Test1]:https://user-images.githubusercontent.com/12142475/77167011-1e645600-6aad-11ea-9ba9-868f092f246b.png







2) Test a three deme model 
First we're estimating the base divergence model between north (HOD, FOR) and South. I'll split each of the vcffiles before reading into R. (This isn't necessary - I only realised later. So for the full dataset I'll just use the single vcf file). 

Then in R: 
```
/Users/alexjvr/2018.postdoc/BrownArgus_2018/201902_DataAnalysis/FastSimCoal/test

source("vcf2sfs.r")  #script

##read in files
southgt <- vcf2gt("South.nomissing.test.recode.vcf", "South.names")
southgt <- vcf2gt("South.nomissing.test.recode.vcf", "South.names.new") ##if all south indivs are seen as a single population

HODgt <- vcf2gt("HOD.nomissing.test.recode.vcf", "HOD.names")
FORgt <- vcf2gt("FOR.nomissing.test.recode.vcf", "FOR.names")


##calculate SFS
mysfs.south <- gt2sfs.raw(southgt,c("BCH","LYD","SWD"))
mysfs.south.new <- gt2sfs.raw(southgt, "South") ##single pop
mysfs.FOR <- gt2sfs.raw(FORgt,"FOR")
mysfs.HOD <- gt2sfs.raw(HODgt,"HOD")



##fold SFS
foldsfs.south <- fold.sfs(mysfs.south)
foldsfs.south.new <- fold.sfs(mysfs.south.new)
foldsfs.HOD <- fold.sfs(mysfs.HOD)
foldsfs.FOR <- fold.sfs(mysfs.FOR)


##plot SFS (can't plot more than 2D

plot.sfs(foldsfs.HOD)
plot.sfs(foldsfs.FOR)

##write files for fastSimCoal

write.1D.fsc(foldsfs.HOD, "foldsfs.HOD")
write.1D.fsc(foldsfs.FOR, "foldsfs.FOR")
write.2D.fsc(foldsfs.south, "foldsfs.south")
write.1D.fsc(foldsfs.south.new, "foldsfs.south.new")
```

![alt_txt][FOR]

[FOR]:https://user-images.githubusercontent.com/12142475/76324228-9d9fa000-62dd-11ea-9527-ce9edf75bf1c.png

![alt_txt][HOD]

[HOD]:https://user-images.githubusercontent.com/12142475/76324232-9e383680-62dd-11ea-9ee0-ef89e9f23909.png


### 2) Priors

I have several parameters that I have to specify priors for. 

I'll use a point value for mutation rate: 

mutation rate - There is only one direct estimate for Lepidoptera (in H. melpomone) [(Keightley et al. 2014b)](https://academic.oup.com/mbe/article/32/1/239/2925597). This is 2.9 × 10−9 (with an upper 95% limit of 5.5 × 10−9). This is similar to in Drosophila: 2.8 × 10−9 per base per haploid genome per generation (with an upper 95% limit of 6.1 × 10−9) [(Keightley et al. 2014a)](https://www.genetics.org/content/196/1/313.short)

nucleotide diversity - estimated [before](https://github.com/alexjvr1/AriciaAgestis_PopGenMS/blob/master/3.GeneticDiversity%26Structure.md)

generation time - Brown argus is bivoltine in the UK, so gen time is 0.5 years. 

Ne = nucleotide diversity / 4xmutation rate = 0.001/(4x (2.9x10^-9)) = 86,206.


### 3) Population input files

For generation of input files see [here](https://speciationgenomics.github.io/fastsimcoal2/) for help. 

The input files need to be named in a consistent way for fastSimCoal2

MAF (or folded SFS)
```
$PREFIX_MAFpop0.obs

mv foldsfs.FOR FOR_MAFpop0.obs
mv foldsfs.HOD HOD_MAFpop0.obs
mv foldsfs.south.new South_MAFpop0.obs

##for multiple populations we need MSFS.obs suffix. And in the fsc2 model specify -multiSFS flag
mv foldsfs.south South_MSFS.obs
```

The population number should follow the tree i.e. South = pop0, HOD = pop1, FOR = pop2. Do I need a multi-dimensional SFS for South? This is what I've created... So, I'll name this accordingly. South_MSFS.obs. Not sure how this will work without pop0 in the title. 
I've created a single MAF file for South where I group all the populations together. This creates a 1D MAF SFS. 



## Scenarios

We're testing three main scenarios. 

1. Col from the south northwards

2. Col from the east

3. Col from the north. 

We'll also include colonisation from all three with mixture between them. 

The scenarios are complicated because we don't know the relationship between all the old populations. So I will run an initial analysis to ascertain the most likely colonisation history of the old populations first. 

```


```


##### ***It is really important to add in a "//Migration matrix x" line if there are any migration matrices. Otherwise the historical events don't get read in properly. 

This is the test model with 2 demes only. 
```
//Number of population samples (demes)
2
//Population effective sizes (number of genes)
NSOUTH
NHOD
//Sample sizes
69
21
//Growth rates	: negative growth implies population expansion
0
//Number of migration matrices : 0 implies no migration between demes
1
//Migration matrix 0
0 MIG10
MIG01 0
//historical event: time, source, sink, migrants, new size, new growth rate, migr. matrix 
1 historical event
TDIV1 0 1 1 RESIZE 0 0
//Number of independent loci [chromosome] 
1 0
//Per chromosome: Number of linkage blocks
1
//per Block: data type, num loci, rec. rate and mut rate + optional parameters
FREQ 1 0 MUTRATE
```


## Folded SFS

Input data needs to be filtered, and the the (joint) folded SFS should be calculated for each of the groups of populations. 

1. North old

2. South old

3. HOD

4. New


### Data filtering: 


```


```


### Split the data into four groups of interest - only if necessary 

Popnames
```
#Extract all sample names
bcftools query -l AA261.0.5miss.9popsMerged.Neutral.recode.vcf

#create files for each population subset
head HOD.popnames 
HOD_10_2013
HOD_1_2013
HOD_12_2014
HOD_14_2013
HOD_15_2014_all
HOD_16_2013
HOD_16_2014


head South.old.popnames 
BCH_10_2013
BCH_1_2014
BCH_12_2013
BCH_12_2014
BCH_14_2014
BCH_15_2013
BCH_15_2014
BCH_16_2013
BCH_19_2013
BCH_19_2014

North.Old.popnames 
FOR_11_2014
FOR_12_2014
FOR_13_2014
FOR_14_2014
FOR_15_2014
FOR_17_2014
FOR_19_2014
FOR_20_2014


```


```
bcftools view -S HOD.popnames AA261.Neutral.thin.recode.vcf > HOD.Neutral.vcf
...After filtering, kept 30 out of 30 Individuals
...After filtering, kept 3486 out of a possible 3486 Sites


bcftools view -S South.old.popnames AA261.Neutral.thin.recode.vcf > South.Neutral.vcf
...After filtering, kept 98 out of 98 Individuals
...After filtering, kept 3486 out of a possible 3486 Sites


bcftools view -S North.Old.popnames AA261.Neutral.thin.recode.vcf > North.Neutral.vcf
...After filtering, kept 20 out of 20 Individuals
...After filtering, kept 3486 out of a possible 3486 Sites


```






